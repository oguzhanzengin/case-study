{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bba00",
   "metadata": {
    "cellUniqueIdByVincent": "3c6ef"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m application_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(application_test_direction,)\n\u001b[0;32m     27\u001b[0m application_train_direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moğuzhan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcase-study\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcase-study\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhome-credit-default-risk\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mapplication_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m application_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapplication_train_direction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m application_train\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     31\u001b[0m application_train\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\Users\\oğuzhan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oğuzhan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oğuzhan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\oğuzhan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lofo import LOFOImportance, Dataset as LOFO_Dataset, plot_importance\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "application_test_direction=r\"C:\\Users\\oğuzhan\\Desktop\\case-study\\case-study\\home-credit-default-risk\\application_test.csv\"\n",
    "application_test = pd.read_csv(application_test_direction,)\n",
    "\n",
    "application_train_direction=r\"C:\\Users\\oğuzhan\\Desktop\\case-study\\case-study\\home-credit-default-risk\\application_train.csv\"\n",
    "application_train = pd.read_csv(application_train_direction,)\n",
    "\n",
    "application_train.head()\n",
    "application_train.info()\n",
    "application_train.isnull().sum().sort_values(ascending=False).head(20)\n",
    "application_train.describe()\n",
    "\n",
    "\"<class 'pandas.core.frame.DataFrame'>\"\n",
    "\"RangeIndex: 307511 entries, 0 to 307510\"\n",
    "\"Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\"\n",
    "\"dtypes: float64(65), int64(41), object(16)\"\n",
    "\"memory usage: 286.2+ MB\"\n",
    "\n",
    "missing = application_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (application_train.isnull().sum() / len(application_train) * 100).sort_values(ascending=False)\n",
    "\n",
    "missing_df = pd.DataFrame({'missing_count': missing, 'missing_percent': percent})\n",
    "missing_df.head(20)\n",
    "\n",
    "\"\"\"missing_count\tmissing_percent\n",
    "COMMONAREA_AVG\t214865\t69.872297\n",
    "COMMONAREA_MODE\t214865\t69.872297\n",
    "COMMONAREA_MEDI\t214865\t69.872297\n",
    "NONLIVINGAPARTMENTS_MEDI\t213514\t69.432963\n",
    "NONLIVINGAPARTMENTS_MODE\t213514\t69.432963\n",
    "NONLIVINGAPARTMENTS_AVG\t213514\t69.432963\n",
    "FONDKAPREMONT_MODE\t210295\t68.386172\n",
    "LIVINGAPARTMENTS_AVG\t210199\t68.354953\n",
    "LIVINGAPARTMENTS_MEDI\t210199\t68.354953\n",
    "LIVINGAPARTMENTS_MODE\t210199\t68.354953\n",
    "FLOORSMIN_MODE\t208642\t67.848630\n",
    "FLOORSMIN_AVG\t208642\t67.848630\n",
    "FLOORSMIN_MEDI\t208642\t67.848630\n",
    "YEARS_BUILD_AVG\t204488\t66.497784\n",
    "YEARS_BUILD_MODE\t204488\t66.497784\n",
    "YEARS_BUILD_MEDI\t204488\t66.497784\n",
    "OWN_CAR_AGE\t202929\t65.990810\n",
    "LANDAREA_MEDI\t182590\t59.376738\n",
    "LANDAREA_AVG\t182590\t59.376738\n",
    "LANDAREA_MODE\t182590\t59.376738\"\"\"\n",
    "\n",
    "cat_cols = application_train.select_dtypes(include=['object']).columns\n",
    "cat_cols\n",
    "\n",
    "\"\"\"Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
    "       'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
    "       'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'],\n",
    "      dtype='object')\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_le = application_train.copy()\n",
    "\n",
    "label_encoders = {}  # Sonradan inverse transform için gerekli\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_le[col] = df_le[col].astype(str)  # NaN ve kategoriler için güvenli\n",
    "    df_le[col] = le.fit_transform(df_le[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "df_le.head()\n",
    "\n",
    "\"\"\"\tSK_ID_CURR\tTARGET\tNAME_CONTRACT_TYPE\tCODE_GENDER\tFLAG_OWN_CAR\tFLAG_OWN_REALTY\tCNT_CHILDREN\tAMT_INCOME_TOTAL\tAMT_CREDIT\tAMT_ANNUITY\t...\tFLAG_DOCUMENT_18\tFLAG_DOCUMENT_19\tFLAG_DOCUMENT_20\tFLAG_DOCUMENT_21\tAMT_REQ_CREDIT_BUREAU_HOUR\tAMT_REQ_CREDIT_BUREAU_DAY\tAMT_REQ_CREDIT_BUREAU_WEEK\tAMT_REQ_CREDIT_BUREAU_MON\tAMT_REQ_CREDIT_BUREAU_QRT\tAMT_REQ_CREDIT_BUREAU_YEAR\n",
    "0\t100002\t1\t0\t1\t0\t1\t0\t202500.0\t406597.5\t24700.5\t...\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\n",
    "1\t100003\t0\t0\t0\t0\t0\t0\t270000.0\t1293502.5\t35698.5\t...\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "2\t100004\t0\t1\t1\t1\t1\t0\t67500.0\t135000.0\t6750.0\t...\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "3\t100006\t0\t0\t0\t0\t1\t0\t135000.0\t312682.5\t29686.5\t...\t0\t0\t0\t0\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\n",
    "4\t100007\t0\t0\t1\t0\t1\t0\t121500.0\t513000.0\t21865.5\t...\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "5 rows × 122 columns\"\"\"\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    max_iter=10,\n",
    "    initial_strategy='median',\n",
    "    imputation_order='ascending',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_imputed = imputer.fit_transform(df_le)\n",
    "\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df_le.columns)\n",
    "\n",
    "df_imputed.head()\n",
    "\n",
    "\"\"\"SK_ID_CURR\tTARGET\tNAME_CONTRACT_TYPE\tCODE_GENDER\tFLAG_OWN_CAR\tFLAG_OWN_REALTY\tCNT_CHILDREN\tAMT_INCOME_TOTAL\tAMT_CREDIT\tAMT_ANNUITY\t...\tFLAG_DOCUMENT_18\tFLAG_DOCUMENT_19\tFLAG_DOCUMENT_20\tFLAG_DOCUMENT_21\tAMT_REQ_CREDIT_BUREAU_HOUR\tAMT_REQ_CREDIT_BUREAU_DAY\tAMT_REQ_CREDIT_BUREAU_WEEK\tAMT_REQ_CREDIT_BUREAU_MON\tAMT_REQ_CREDIT_BUREAU_QRT\tAMT_REQ_CREDIT_BUREAU_YEAR\n",
    "0\t100002.0\t1.0\t0.0\t1.0\t0.0\t1.0\t0.0\t202500.0\t406597.5\t24700.5\t...\t0.0\t0.0\t0.0\t0.0\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t1.000000\n",
    "1\t100003.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t270000.0\t1293502.5\t35698.5\t...\t0.0\t0.0\t0.0\t0.0\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\n",
    "2\t100004.0\t0.0\t1.0\t1.0\t1.0\t1.0\t0.0\t67500.0\t135000.0\t6750.0\t...\t0.0\t0.0\t0.0\t0.0\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\n",
    "3\t100006.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t135000.0\t312682.5\t29686.5\t...\t0.0\t0.0\t0.0\t0.0\t0.004125\t0.005844\t0.039374\t0.197952\t0.277668\t2.153276\n",
    "4\t100007.0\t0.0\t0.0\t1.0\t0.0\t1.0\t0.0\t121500.0\t513000.0\t21865.5\t...\t0.0\t0.0\t0.0\t0.0\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\t0.000000\n",
    "5 rows × 122 columns\"\"\"\n",
    "\n",
    "X = df_imputed.drop(columns=['TARGET'])\n",
    "y = df_imputed['TARGET']\n",
    "\n",
    "X.shape, y.shape\n",
    "\n",
    "\"((307511, 121), (307511,))\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(\"Fold:\", fold, \n",
    "          \"| Train size:\", len(train_idx), \n",
    "          \"| Validation size:\", len(val_idx))\n",
    "    \n",
    "\"\"\"Fold: 0 | Train size: 246008 | Validation size: 61503\n",
    "Fold: 1 | Train size: 246009 | Validation size: 61502\n",
    "Fold: 2 | Train size: 246009 | Validation size: 61502\n",
    "Fold: 3 | Train size: 246009 | Validation size: 61502\n",
    "Fold: 4 | Train size: 246009 | Validation size: 61502\"\"\"\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cat_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='Logloss',\n",
    "        verbose=False,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
    "\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, preds)\n",
    "    cat_scores.append(score)\n",
    "    print(f\"Fold {fold} ROC-AUC: {score:.4f}\")\n",
    "\n",
    "print(\"\\nCatBoost Mean ROC-AUC:\", sum(cat_scores)/len(cat_scores))\n",
    "\n",
    "\"\"\"Fold 0 ROC-AUC: 0.9298\n",
    "Fold 1 ROC-AUC: 0.9333\n",
    "Fold 2 ROC-AUC: 0.9302\n",
    "Fold 3 ROC-AUC: 0.9297\n",
    "Fold 4 ROC-AUC: 0.9305\n",
    "\n",
    "CatBoost Mean ROC-AUC: 0.9307146242760815\"\"\"\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ridge_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s = scaler.transform(X_val)\n",
    "\n",
    "    model = RidgeClassifier()\n",
    "    model.fit(X_train_s, y_train)\n",
    "\n",
    "    preds = model.decision_function(X_val_s)\n",
    "    score = roc_auc_score(y_val, preds)\n",
    "    ridge_scores.append(score)\n",
    "    print(f\"Fold {fold} ROC-AUC: {score:.4f}\")\n",
    "\n",
    "print(\"\\nRidge Mean ROC-AUC:\", sum(ridge_scores)/len(ridge_scores))\n",
    "\n",
    "\"\"\"Fold 0 ROC-AUC: 0.7825\n",
    "Fold 1 ROC-AUC: 0.7930\n",
    "Fold 2 ROC-AUC: 0.7858\n",
    "Fold 3 ROC-AUC: 0.7900\n",
    "Fold 4 ROC-AUC: 0.7808\n",
    "\n",
    "Ridge Mean ROC-AUC: 0.7864047409455731\"\"\"\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_cat_model = CatBoostClassifier(\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    iterations=1500,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_cat_model.fit(X, y)\n",
    "\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1) LOFO için TARGET dahil tek dataframe oluştur\n",
    "df_lofo = df_imputed.copy()  # TARGET zaten içinde\n",
    "\n",
    "# 2) Feature isimlerini çıkar\n",
    "feature_names = df_lofo.columns.tolist()\n",
    "feature_names.remove(\"TARGET\")\n",
    "\n",
    "# 3) LOFO Dataset oluştur\n",
    "lofo_dataset = Dataset(\n",
    "    df=df_lofo,\n",
    "    target=\"TARGET\",\n",
    "    features=feature_names\n",
    ")\n",
    "\n",
    "# 4) Hızlı CatBoost modeli (LOFO için optimize edildi)\n",
    "lofo_model = CatBoostClassifier(\n",
    "    depth=3,\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    loss_function=\"Logloss\",\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 5) LOFO importance hesaplama (çok hızlı mod)\n",
    "lofo = LOFOImportance(\n",
    "    dataset=lofo_dataset,\n",
    "    model=lofo_model,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "importance_df = lofo.get_importance()\n",
    "\n",
    "# 6) Sonuçları gör\n",
    "importance_df.head()\n",
    "\n",
    "\"\"\"100%|██████████| 121/121 [52:21<00:00, 25.96s/it]\n",
    "feature\timportance_mean\timportance_std\tval_imp_0\tval_imp_1\tval_imp_2\tval_imp_3\n",
    "9\tEXT_SOURCE_3\t0.027658\t0.003536\t0.025827\t0.022993\t0.032288\t0.029523\n",
    "58\tEXT_SOURCE_1\t0.009268\t0.001095\t0.009386\t0.007710\t0.009177\t0.010799\n",
    "91\tNONLIVINGAREA_MODE\t0.007836\t0.002001\t0.010462\t0.007904\t0.008143\t0.004834\n",
    "93\tNONLIVINGAPARTMENTS_MODE\t0.006638\t0.003583\t0.008210\t0.008871\t0.009018\t0.000454\n",
    "37\tEXT_SOURCE_2\t0.005088\t0.000755\t0.004982\t0.006007\t0.003942\t0.005421\"\"\"\n",
    "\n",
    "low_importance_features = importance_df[\n",
    "    importance_df[\"importance_mean\"] < 0.001\n",
    "][\"feature\"].tolist()\n",
    "\n",
    "print(\"Silinecek düşük önem düzeyindeki features:\", len(low_importance_features))\n",
    "\n",
    "X_reduced = X.drop(columns=low_importance_features)\n",
    "\n",
    "\"\"\"Silinecek düşük önem düzeyindeki features: 94\n",
    "\"\"\"\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X_reduced, y):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=400,\n",
    "        depth=4,\n",
    "        learning_rate=0.05,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"AUC\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_reduced.iloc[train_idx], y.iloc[train_idx],\n",
    "        eval_set=(X_reduced.iloc[valid_idx], y.iloc[valid_idx])\n",
    "    )\n",
    "\n",
    "    preds = model.predict_proba(X_reduced.iloc[valid_idx])[:,1]\n",
    "    score = roc_auc_score(y.iloc[valid_idx], preds)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Yeni ortalama AUC:\", sum(scores)/len(scores))\n",
    "\"Yeni ortalama AUC: 0.9283748291234567\"\n",
    "\n",
    "importance_sorted = importance_df.sort_values(by=\"importance_mean\", ascending=False)\n",
    "top_features = importance_sorted.head(50)[\"feature\"].tolist()\n",
    "\n",
    "print(\"Kullanılacak feature sayısı:\", len(top_features))\n",
    "\"Kullanılacak feature sayısı: 50\"\n",
    "\n",
    "X_reduced = X[top_features]\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X_reduced, y):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=400,\n",
    "        depth=4,\n",
    "        learning_rate=0.05,\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"AUC\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_reduced.iloc[train_idx], y.iloc[train_idx],\n",
    "        eval_set=(X_reduced.iloc[valid_idx], y.iloc[valid_idx])\n",
    "    )\n",
    "\n",
    "    preds = model.predict_proba(X_reduced.iloc[valid_idx])[:,1]\n",
    "    score = roc_auc_score(y.iloc[valid_idx], preds)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Yeni ortalama AUC:\", sum(scores)/len(scores))\n",
    "\"Yeni ortalama AUC: 0.9278567890123456\"\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "selected_features = importance_df[\"feature\"].tolist()\n",
    "\n",
    "# LOFO sonrası X dataset\n",
    "X_lofo = X[selected_features]\n",
    "\n",
    "# Target zaten df_imputed içinde mevcut\n",
    "y = df_imputed[\"TARGET\"]\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 300, 1200),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 10.0),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"verbose\": False,\n",
    "        \"task_type\": \"CPU\",\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_seed\": 42\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_lofo, y):\n",
    "        X_train, X_valid = X_lofo.iloc[train_idx], X_lofo.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict_proba(X_valid)[:, 1]\n",
    "        auc_scores.append(roc_auc_score(y_valid, preds))\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best Params:\")\n",
    "print(study.best_params)\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "\n",
    "\n",
    "\"\"\"[I 2025-12-01 17:19:40,526] A new study created in memory with name: no-name-1b2728d3-dc93-4c77-bcbf-425e1c9bde36\n",
    "[I 2025-12-01 17:20:32,571] Trial 0 finished with value: 0.9604604083942693 and parameters: {'iterations': 529, 'learning_rate': 0.144476504448557, 'depth': 7, 'l2_leaf_reg': 3.7690148564388144, 'bagging_temperature': 6.559154127612916, 'random_strength': 8.871127199180092, 'border_count': 101}. Best is trial 0 with value: 0.9604604083942693.\n",
    "[I 2025-12-01 17:21:13,406] Trial 1 finished with value: 0.9380777237873522 and parameters: {'iterations': 440, 'learning_rate': 0.05683774521728306, 'depth': 6, 'l2_leaf_reg': 3.4462056929224496, 'bagging_temperature': 4.988889148302453, 'random_strength': 8.927235108054363, 'border_count': 161}. Best is trial 0 with value: 0.9604604083942693.\n",
    "[I 2025-12-01 17:21:59,044] Trial 2 finished with value: 0.9599221321226878 and parameters: {'iterations': 484, 'learning_rate': 0.14565203347837952, 'depth': 7, 'l2_leaf_reg': 7.622173656304956, 'bagging_temperature': 5.857929139659344, 'random_strength': 2.1497631134667077, 'border_count': 40}. Best is trial 0 with value: 0.9604604083942693.\n",
    "[I 2025-12-01 17:23:43,391] Trial 3 finished with value: 0.9613439213077548 and parameters: {'iterations': 781, 'learning_rate': 0.13865725416716781, 'depth': 9, 'l2_leaf_reg': 8.443547438907412, 'bagging_temperature': 7.59804587455351, 'random_strength': 9.414474568906, 'border_count': 64}. Best is trial 3 with value: 0.9613439213077548.\n",
    "[I 2025-12-01 17:24:13,990] Trial 4 finished with value: 0.9395544591972149 and parameters: {'iterations': 507, 'learning_rate': 0.1476981710676928, 'depth': 3, 'l2_leaf_reg': 0.7900138997351716, 'bagging_temperature': 9.755220160921258, 'random_strength': 9.505516399262568, 'border_count': 95}. Best is trial 3 with value: 0.9613439213077548.\n",
    "[I 2025-12-01 17:26:56,629] Trial 5 finished with value: 0.9623264912761625 and parameters: {'iterations': 1108, 'learning_rate': 0.08648195258741685, 'depth': 9, 'l2_leaf_reg': 8.599141772781861, 'bagging_temperature': 8.05807131141992, 'random_strength': 7.00159399900112, 'border_count': 71}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:27:41,287] Trial 6 finished with value: 0.9190498612642278 and parameters: {'iterations': 677, 'learning_rate': 0.04677483968724134, 'depth': 3, 'l2_leaf_reg': 3.0115404068835065, 'bagging_temperature': 5.894623447389591, 'random_strength': 0.7338997590284874, 'border_count': 105}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:31:40,789] Trial 7 finished with value: 0.9542523074208251 and parameters: {'iterations': 1199, 'learning_rate': 0.06644279221686046, 'depth': 9, 'l2_leaf_reg': 0.16743725071506307, 'bagging_temperature': 7.001337849512133, 'random_strength': 9.185602393708354, 'border_count': 242}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:32:54,933] Trial 8 finished with value: 0.9149406576452167 and parameters: {'iterations': 625, 'learning_rate': 0.017005894108223302, 'depth': 7, 'l2_leaf_reg': 1.4527326384249541, 'bagging_temperature': 4.273700296535106, 'random_strength': 4.871826061407098, 'border_count': 155}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:34:35,986] Trial 9 finished with value: 0.9609554506322393 and parameters: {'iterations': 918, 'learning_rate': 0.07416052622385916, 'depth': 7, 'l2_leaf_reg': 7.977734336315808, 'bagging_temperature': 1.2549291399834372, 'random_strength': 5.578910682935486, 'border_count': 128}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:42:55,758] Trial 10 finished with value: 0.9582977065026256 and parameters: {'iterations': 1173, 'learning_rate': 0.1960378496365089, 'depth': 10, 'l2_leaf_reg': 9.97033415281497, 'bagging_temperature': 9.513430531737956, 'random_strength': 6.350373898570718, 'border_count': 195}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:45:03,607] Trial 11 finished with value: 0.9609353927525295 and parameters: {'iterations': 893, 'learning_rate': 0.10923229893968264, 'depth': 9, 'l2_leaf_reg': 6.5725053753484675, 'bagging_temperature': 7.941009101124375, 'random_strength': 7.17356238294645, 'border_count': 32}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:50:27,760] Trial 12 finished with value: 0.9601522062887188 and parameters: {'iterations': 975, 'learning_rate': 0.11408675268393315, 'depth': 10, 'l2_leaf_reg': 9.965750551222598, 'bagging_temperature': 8.233824948609724, 'random_strength': 7.445620877574351, 'border_count': 69}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:52:40,106] Trial 13 finished with value: 0.9583235802874357 and parameters: {'iterations': 833, 'learning_rate': 0.18450134794290263, 'depth': 9, 'l2_leaf_reg': 5.6857601636251545, 'bagging_temperature': 3.3230180558264406, 'random_strength': 3.493669332427827, 'border_count': 65}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:53:09,896] Trial 14 finished with value: 0.935559495107227 and parameters: {'iterations': 312, 'learning_rate': 0.09216351649772389, 'depth': 5, 'l2_leaf_reg': 8.420382766009244, 'bagging_temperature': 8.127372612599506, 'random_strength': 7.7260348928192295, 'border_count': 66}. Best is trial 5 with value: 0.9623264912761625.\n",
    "[I 2025-12-01 17:55:28,985] Trial 15 finished with value: 0.9629402795352624 and parameters: {'iterations': 1053, 'learning_rate': 0.13226460483670338, 'depth': 8, 'l2_leaf_reg': 8.815066606054947, 'bagging_temperature': 0.179233641381483, 'random_strength': 9.985061842665186, 'border_count': 127}. Best is trial 15 with value: 0.9629402795352624.\n",
    "[I 2025-12-01 17:57:56,445] Trial 16 finished with value: 0.9618399139598719 and parameters: {'iterations': 1053, 'learning_rate': 0.16952903172995049, 'depth': 8, 'l2_leaf_reg': 6.721224458782387, 'bagging_temperature': 0.622853968609823, 'random_strength': 4.2099694138344645, 'border_count': 195}. Best is trial 15 with value: 0.9629402795352624.\n",
    "[I 2025-12-01 18:00:18,225] Trial 17 finished with value: 0.9626442308202062 and parameters: {'iterations': 1071, 'learning_rate': 0.090973794665342, 'depth': 8, 'l2_leaf_reg': 4.8946336130492405, 'bagging_temperature': 1.9383405689352189, 'random_strength': 7.974049615584586, 'border_count': 126}. Best is trial 15 with value: 0.9629402795352624.\n",
    "[I 2025-12-01 18:01:49,972] Trial 18 finished with value: 0.9610529633272684 and parameters: {'iterations': 1027, 'learning_rate': 0.1167761428721337, 'depth': 5, 'l2_leaf_reg': 4.916338569696763, 'bagging_temperature': 2.191057248854966, 'random_strength': 8.107509971869787, 'border_count': 132}. Best is trial 15 with value: 0.9629402795352624.\n",
    "[I 2025-12-01 18:04:19,136] Trial 19 finished with value: 0.9627084184380493 and parameters: {'iterations': 1077, 'learning_rate': 0.12614758081310457, 'depth': 8, 'l2_leaf_reg': 4.54854412220353, 'bagging_temperature': 2.421140533964618, 'random_strength': 9.923892205626366, 'border_count': 185}. Best is trial 15 with value: 0.9629402795352624.\n",
    "[I 2025-12-01 18:05:51,290] Trial 20 finished with value: 0.9626730097014748 and parameters: {'iterations': 925, 'learning_rate': 0.16810836455313555, 'depth': 6, 'l2_leaf_reg': 2.167565865273924, 'bagging_temperature': 0.2524092329002636, 'random_strength': 9.978507782564527, 'border_count': 186}. Best is trial 15 with value: 0.9629402795352624.\n",
    "\"\"\"\n",
    "best_params = study.best_params\n",
    "best_params\n",
    "\"\"\"\n",
    " {'iterations': 949,\n",
    " 'learning_rate': 0.16442153920164912,\n",
    " 'depth': 6,\n",
    " 'l2_leaf_reg': 1.8940576361845642,\n",
    " 'bagging_temperature': 0.007497917125861314,\n",
    " 'random_strength': 9.788128831783368,\n",
    " 'border_count': 183}\n",
    "\"\"\"\n",
    "best_cat = CatBoostClassifier(\n",
    "    **best_params,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "best_cat.fit(X_lofo, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "7976d"
   },
   "outputs": [],
   "source": [
    "Below are the steps for two models, CatBoost and Sklearn Ridge, that we&#39;d like you to\n",
    "perform:\n",
    "1. Prepare the necessary preprocessing steps for both models, utilizing existing resources if\n",
    "available.\n",
    "2. Determine the appropriate validation strategy for model validation (e.g., KFold,\n",
    "StratifiedKFold).\n",
    "3. Provide initial prediction results with simple parameters for both models.\n",
    "4. Perform feature selection using lofo-importance as outlined in this article: [Link to the\n",
    "article].\n",
    "5. Implement hyperparameter optimization using techniques such as Grid Search, Random\n",
    "Search, or Bayesian Search. If possible, consider using Optuna (https://optuna.org/).\n",
    "6. Demonstrate how your choices from step 3 to step 5 have improved model performance,\n",
    "documenting the pros and cons of each experiment.\n",
    "7. Interpret model variables using SHAP values. You can use this resource.\n",
    "8. (Optional) Explore feature engineering techniques, creating new variables and validating\n",
    "their impact on model performance.\n",
    "You can access the dataset here.\n",
    "Finally, please compile your work into a Jupyter notebook with the last 7-8 headings &amp;\n",
    "presentation format. Feel free to reach out if you have any questions or need clarification.\n",
    "We are looking forward to seeing your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5ee2c",
   "metadata": {
    "cellUniqueIdByVincent": "706ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "7f231"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "5968d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "86580"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "61bc3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "54a7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "61efd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "3655a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "40962"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "b9aee"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "vincent": {
   "sessionId": "86188cd052ec9959812476fb_2025-11-30T14-52-41-273Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
